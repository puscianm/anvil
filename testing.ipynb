{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fbf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import anvil\n",
    "import anvil.adaround\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import os, pathlib\n",
    "\n",
    "base_path = pathlib.Path(\"/home/mpuscian/Desktop/repozytoria/MINI_projects/anvil/models/\")\n",
    "model_path = base_path.joinpath(\"cifar_model2.pth\")\n",
    "adaround_model_path = base_path.joinpath(\"adaround_model.pth\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "adaround_model = copy.deepcopy(model)\n",
    "adaround_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Stwórz wejście testowe (np. batch 1 obrazka)\n",
    "sample_input = torch.randn(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cacb020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    module = adaround_model.conv1\n",
    "\n",
    "    captured_input = None\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        nonlocal captured_input\n",
    "        captured_input = input[0].detach()\n",
    "\n",
    "    hook = module.register_forward_hook(hook_fn)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = adaround_model(sample_input)\n",
    "\n",
    "    hook.remove()\n",
    "\n",
    "    if captured_input is None:\n",
    "        raise RuntimeError(f\"Nie udało się przechwycić wejścia do warstwy conv1\")\n",
    "\n",
    "    # Kwantyzacja wag\n",
    "    quantized_weights = anvil.adaround.adaround_layer(module, captured_input)\n",
    "\n",
    "    return quantized_weights, captured_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26a31b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final h_alpha: tensor([[[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "qw, cap_inp = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad530140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1177, -0.0938, -0.1177],\n",
       "        [ 0.1894, -0.0598, -0.0787],\n",
       "        [-0.1001, -0.1315,  0.1869]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18f02252",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc, zp = anvil.adaround.get_qparams(qw[0][0], qmin=-128, qmax=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00792409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-117,  -98, -117],\n",
       "        [ 127,  -70,  -86],\n",
       "        [-103, -128,  126]], dtype=torch.int8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(qw[0][0] / sc + zp).clamp(-128, 127).to(torch.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bf0b4",
   "metadata": {},
   "source": [
    "# Layer quantization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd88d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final h_alpha: tensor([[[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "inputs = cap_inp\n",
    "num_iterations=1000\n",
    "beta_range=(20, 2)\n",
    "reg_param=0.01\n",
    "per_channel=True\n",
    "\n",
    "layer = adaround_model.conv1\n",
    "\n",
    "signed = False  # Można rozpoznać np. po typie aktywacji\n",
    "qmin, qmax = (-128, 127) if signed else (0, 255)\n",
    "\n",
    "weight = layer.weight.detach()\n",
    "alpha = nn.Parameter(torch.zeros_like(weight))\n",
    "scale_w, zp_w = anvil.adaround.get_qparams(weight, qmin, qmax, per_channel=True, channel_axis=0)\n",
    "\n",
    "optimizer = torch.optim.Adam([alpha], lr=1e-2)\n",
    "best_loss = float(\"inf\")\n",
    "best_alpha = alpha.data.clone()\n",
    "\n",
    "# Kwantyzacja wejścia (per-tensor)\n",
    "scale_in, zp_in = anvil.adaround.get_qparams(inputs, qmin, qmax, per_channel=False)\n",
    "inputs_q = anvil.adaround.quantize_tensor(inputs, scale_in, zp_in, qmin, qmax)\n",
    "\n",
    "for step in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Kwantyzacja wag\n",
    "    weight_q = anvil.adaround.adaround_weight(weight / scale_w + zp_w, alpha)\n",
    "    weight_q = scale_w * (weight_q - zp_w)\n",
    "\n",
    "    # Forward oryginalny vs. kwantyzowany\n",
    "    out_fp = layer(inputs)\n",
    "    out_q = F.conv2d(inputs_q, weight_q, bias=layer.bias, stride=layer.stride,\n",
    "                        padding=layer.padding, dilation=layer.dilation, groups=layer.groups)\n",
    "\n",
    "    loss_data = F.mse_loss(out_q, out_fp)\n",
    "\n",
    "    beta = beta_range[0] * (1 - step / num_iterations) + beta_range[1] * (step / num_iterations)\n",
    "    h_alpha = torch.clamp(torch.sigmoid(alpha) * 1.2 - 0.1, 0, 1) #according to up and down\n",
    "    reg = torch.sum(1 - torch.abs(2 * h_alpha - 1) ** beta)\n",
    "\n",
    "    loss = loss_data + reg_param * reg\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        best_alpha = alpha.data.clone()\n",
    "\n",
    "# Finalizacja\n",
    "h_alpha = torch.clamp(torch.sigmoid(best_alpha) * 1.2 - 0.1, 0, 1)\n",
    "print(f\"final h_alpha: {h_alpha}\")\n",
    "final_w_q = scale_w * (torch.floor(weight / scale_w + zp_w) + h_alpha - zp_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31a18fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9440)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_q[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6117e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-456.,  328.,  555.,  678.,  155.,  676.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.Tensor([-456., 328., 555., 678., 155., 676.])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aeecfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (tensor.max() - tensor.min())/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d11ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-103,   73,  124, -104,   34, -104], dtype=torch.int8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(tensor/s).to(torch.int8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anvil",
   "language": "python",
   "name": "anvil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
