{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2729c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "base_path = pathlib.Path(\"/home/mpuscian/Desktop/repozytoria/MINI_projects/anvil/models/\")\n",
    "cifar_model_path = base_path.joinpath(\"cifar_model.pth\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "adaround = copy.deepcopy(model)\n",
    "\n",
    "adaround.load_state_dict(torch.load(cifar_model_path))\n",
    "adaround.eval().to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 3. Datasets\n",
    "full_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_size = int(0.9 * len(full_train_dataset))  # 45,000\n",
    "val_size = len(full_train_dataset) - train_size  # 5,000\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# 4. DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=6)\n",
    "val_dataset.dataset.transform = transform_test\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "val_dataset = val_loader.dataset  # your full val dataset\n",
    "\n",
    "num_samples = len(val_dataset)\n",
    "subset_size = num_samples // 5\n",
    "\n",
    "# Randomly sample 1/5 indices\n",
    "all_indices = np.arange(num_samples)\n",
    "np.random.shuffle(all_indices)\n",
    "subset_indices = all_indices[:subset_size]\n",
    "\n",
    "# Create a sampler using those indices\n",
    "sampler = SubsetRandomSampler(subset_indices)\n",
    "\n",
    "# Create DataLoader with this sampler\n",
    "subset_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=val_loader.batch_size,\n",
    "    sampler=sampler,\n",
    "    num_workers=val_loader.num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07b2c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.13/abc.py:106: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n",
      "  cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:37,336 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-06-21 12:25:37,354 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-06-21 12:25:37,354 - Quant - INFO - Unsupported op type Mean\n",
      "2025-06-21 12:25:37,355 - Quant - INFO - Unsupported op type Unsqueeze\n",
      "2025-06-21 12:25:37,355 - Quant - INFO - Unsupported op type Compress\n",
      "2025-06-21 12:25:37,355 - Quant - INFO - Unsupported op type Identity\n",
      "2025-06-21 12:25:37,355 - Quant - INFO - Unsupported op type Shape\n",
      "2025-06-21 12:25:37,355 - Quant - INFO - Unsupported op type If\n",
      "2025-06-21 12:25:37,357 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:None\n",
      "2025-06-21 12:25:38,232 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-06-21 12:25:38,336 - Utils - INFO - Caching 8 batches from data loader at path location: /tmp/tmp70akwl8y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:38,342 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                               | 0/60 [00:00<?, ?it/s]/home/mpuscian/Envs/Optimization/lib64/python3.13/site-packages/aimet_torch/_base/adaround/adaround_optimizer.py:257: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  return float(recons_err_hard), float(recons_err_soft)\n",
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:40,631 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:43,071 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:45,462 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:47,888 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:50,307 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:52,836 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:55,183 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:57,459 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:25:59,839 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:02,253 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:04,533 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:06,846 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:09,114 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:11,579 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:13,949 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:16,586 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:20,878 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:23,353 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:27,769 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:32,202 - Quant - INFO - Started Optimizing weight rounding of module: fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:56<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:26:34,613 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from aimet_common.defs import QuantScheme\n",
    "\n",
    "def calibration_data_loader():\n",
    "    for i, (x, _) in enumerate(val_loader):\n",
    "        yield x.to(device)\n",
    "        if i >= 9:  # Limit to 10 batches, as specified in AdaroundParameters\n",
    "            break\n",
    "\n",
    "\n",
    "params = AdaroundParameters(\n",
    "    data_loader=subset_loader,\n",
    "    num_batches=min(10, len(subset_loader)),\n",
    "    default_num_iterations=3000,\n",
    "    default_reg_param=0.07,\n",
    "    default_beta_range=(40, 2)\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "adaround = Adaround.apply_adaround(\n",
    "    model=adaround,\n",
    "    dummy_input=dummy_input,\n",
    "    params=params,\n",
    "    path=base_path.joinpath('aimet/adaround_encodings'),\n",
    "    filename_prefix='resnet18',\n",
    "    default_param_bw=6,\n",
    "    default_quant_scheme=QuantScheme.post_training_tf_enhanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8476ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model first layer device: cuda:0\n",
      "Dummy input device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model first layer device: {next(adaround.parameters()).device}\")\n",
    "print(f\"Dummy input device: {dummy_input.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc4bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-21 12:27:10,116 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-06-21 12:27:10,134 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-06-21 12:27:10,134 - Quant - INFO - Unsupported op type Mean\n",
      "2025-06-21 12:27:10,134 - Quant - INFO - Unsupported op type Unsqueeze\n",
      "2025-06-21 12:27:10,135 - Quant - INFO - Unsupported op type Compress\n",
      "2025-06-21 12:27:10,135 - Quant - INFO - Unsupported op type Identity\n",
      "2025-06-21 12:27:10,135 - Quant - INFO - Unsupported op type Shape\n",
      "2025-06-21 12:27:10,135 - Quant - INFO - Unsupported op type If\n",
      "2025-06-21 12:27:10,136 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:None\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(model, _ =  None):\n",
    "    for batch in calibration_data_loader():\n",
    "        model(batch)\n",
    "\n",
    "sim = QuantizationSimModel(\n",
    "    model=adaround,\n",
    "    dummy_input=dummy_input,\n",
    "    quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "    default_output_bw=4,\n",
    "    default_param_bw=4,\n",
    ")\n",
    "sim.compute_encodings(forward_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9de2a9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ee039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c633b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b8890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unquantized_model = copy.deepcopy(model)\n",
    "\n",
    "unquantized_model.load_state_dict(torch.load(cifar_model_path))\n",
    "unquantized_model = unquantized_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c824929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaround (testset) 4 bits AIMET: 0.7668\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = evaluate_model(sim.model, test_loader, device)\n",
    "print(f\"Adaround (testset) 4 bits AIMET: {metrics.accuracy_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5632b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaround (testset) 6 bits AIMET: 0.7659\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = evaluate_model(sim.model, test_loader, device)\n",
    "print(f\"Adaround (testset) 6 bits AIMET: {metrics.accuracy_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2338d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2497, -0.2374, -0.2355,  ...,  0.2353,  0.2356,  0.2504],\n",
       "       device='cuda:0', grad_fn=<Unique2Backward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(sim.model.conv1.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anvil",
   "language": "python",
   "name": "anvil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
