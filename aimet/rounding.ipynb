{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2729c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "base_path = pathlib.Path(\"/home/mpuscian/Desktop/repozytoria/MINI_projects/anvil/models/\")\n",
    "cifar_model_path = base_path.joinpath(\"cifar_model.pth\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "adaround = copy.deepcopy(model)\n",
    "\n",
    "adaround.load_state_dict(torch.load(cifar_model_path))\n",
    "adaround.eval().to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 3. Datasets\n",
    "full_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_size = int(0.9 * len(full_train_dataset))  # 45,000\n",
    "val_size = len(full_train_dataset) - train_size  # 5,000\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# 4. DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=6)\n",
    "val_dataset.dataset.transform = transform_test\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "val_dataset = val_loader.dataset  # your full val dataset\n",
    "\n",
    "num_samples = len(val_dataset)\n",
    "subset_size = num_samples // 5\n",
    "\n",
    "# Randomly sample 1/5 indices\n",
    "all_indices = np.arange(num_samples)\n",
    "np.random.shuffle(all_indices)\n",
    "subset_indices = all_indices[:subset_size]\n",
    "\n",
    "# Create a sampler using those indices\n",
    "sampler = SubsetRandomSampler(subset_indices)\n",
    "\n",
    "# Create DataLoader with this sampler\n",
    "subset_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=val_loader.batch_size,\n",
    "    sampler=sampler,\n",
    "    num_workers=val_loader.num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07b2c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:56:59,331 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-05-28 15:56:59,349 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-05-28 15:56:59,349 - Quant - INFO - Unsupported op type Mean\n",
      "2025-05-28 15:56:59,349 - Quant - INFO - Unsupported op type Unsqueeze\n",
      "2025-05-28 15:56:59,349 - Quant - INFO - Unsupported op type Compress\n",
      "2025-05-28 15:56:59,349 - Quant - INFO - Unsupported op type Identity\n",
      "2025-05-28 15:56:59,350 - Quant - INFO - Unsupported op type Shape\n",
      "2025-05-28 15:56:59,350 - Quant - INFO - Unsupported op type If\n",
      "2025-05-28 15:56:59,351 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:None\n",
      "2025-05-28 15:57:00,089 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-05-28 15:57:00,196 - Utils - INFO - Caching 8 batches from data loader at path location: /tmp/tmpovkds60d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:00,200 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:02,247 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:04,531 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:06,837 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:09,152 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:11,492 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:13,891 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:16,159 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:18,530 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:20,790 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:23,085 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:25,329 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:27,564 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:29,743 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:32,000 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:34,289 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:36,642 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:40,569 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:42,762 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:46,829 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:50,917 - Quant - INFO - Started Optimizing weight rounding of module: fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:52<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:57:53,096 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from aimet_common.defs import QuantScheme\n",
    "\n",
    "def calibration_data_loader():\n",
    "    for i, (x, _) in enumerate(val_loader):\n",
    "        yield x.to(device)\n",
    "        if i >= 9:  # Limit to 10 batches, as specified in AdaroundParameters\n",
    "            break\n",
    "\n",
    "\n",
    "params = AdaroundParameters(\n",
    "    data_loader=subset_loader,\n",
    "    num_batches=min(10, len(subset_loader)),\n",
    "    default_num_iterations=3000,\n",
    "    default_reg_param=0.07,\n",
    "    default_beta_range=(40, 2)\n",
    ")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "adaround = Adaround.apply_adaround(\n",
    "    model=adaround,\n",
    "    dummy_input=dummy_input,\n",
    "    params=params,\n",
    "    path=base_path.joinpath('aimet/adaround_encodings'),\n",
    "    filename_prefix='resnet18',\n",
    "    default_param_bw=4,\n",
    "    default_quant_scheme=QuantScheme.post_training_tf_enhanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8476ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model first layer device: cuda:0\n",
      "Dummy input device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model first layer device: {next(adaround.parameters()).device}\")\n",
    "print(f\"Dummy input device: {dummy_input.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc4bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 16:00:11,700 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-05-28 16:00:11,718 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-05-28 16:00:11,718 - Quant - INFO - Unsupported op type Mean\n",
      "2025-05-28 16:00:11,718 - Quant - INFO - Unsupported op type Unsqueeze\n",
      "2025-05-28 16:00:11,719 - Quant - INFO - Unsupported op type Compress\n",
      "2025-05-28 16:00:11,719 - Quant - INFO - Unsupported op type Identity\n",
      "2025-05-28 16:00:11,719 - Quant - INFO - Unsupported op type Shape\n",
      "2025-05-28 16:00:11,719 - Quant - INFO - Unsupported op type If\n",
      "2025-05-28 16:00:11,720 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:None\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(model, _ =  None):\n",
    "    for batch in calibration_data_loader():\n",
    "        model(batch)\n",
    "\n",
    "sim = QuantizationSimModel(\n",
    "    model=adaround,\n",
    "    dummy_input=dummy_input,\n",
    "    quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "    default_output_bw=4,\n",
    "    default_param_bw=4,\n",
    ")\n",
    "sim.compute_encodings(forward_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9de2a9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ee039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b8890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unquantized_model = copy.deepcopy(model)\n",
    "\n",
    "unquantized_model.load_state_dict(torch.load(cifar_model_path))\n",
    "unquantized_model = unquantized_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f40d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unquantized model accuracy(TRAIN): 92.40%\n",
      "Unquantized model accuracy(TEST): 82.58%\n",
      "Quantized model accuracy(TRAIN): 87.08%\n",
      "Quantized model accuracy(TEST): 78.85%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unquantized model accuracy(TRAIN): {evaluate_model(unquantized_model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Unquantized model accuracy(TEST): {evaluate_model(unquantized_model, test_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TRAIN): {evaluate_model(sim.model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TEST): {evaluate_model(sim.model, test_loader, device) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c824929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unquantized model accuracy(TRAIN): 92.46%\n",
      "Unquantized model accuracy(TEST): 82.58%\n",
      "Quantized model accuracy(TRAIN): 92.37%\n",
      "Quantized model accuracy(TEST): 82.50%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unquantized model accuracy(TRAIN): {evaluate_model(unquantized_model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Unquantized model accuracy(TEST): {evaluate_model(unquantized_model, test_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TRAIN): {evaluate_model(sim.model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TEST): {evaluate_model(sim.model, test_loader, device) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a07b4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unquantized model accuracy(TRAIN): 92.46%\n",
      "Unquantized model accuracy(TEST): 82.58%\n",
      "Quantized model accuracy(TRAIN): 92.38%\n",
      "Quantized model accuracy(TEST): 82.48%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unquantized model accuracy(TRAIN): {evaluate_model(unquantized_model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Unquantized model accuracy(TEST): {evaluate_model(unquantized_model, test_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TRAIN): {evaluate_model(sim.model, train_loader, device) * 100:.2f}%\")\n",
    "print(f\"Quantized model accuracy(TEST): {evaluate_model(sim.model, test_loader, device) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anvil",
   "language": "python",
   "name": "anvil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
